{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 10 \u2014 EUR/USD Future Test (Unseen Data Evaluation)\n",
        "\n",
        "**Goal**\n",
        "- Load the frozen EUR/USD model trained in notebook **09**\n",
        "- Load **new unseen EUR/USD data** (future period)\n",
        "- Recompute the same features\n",
        "- Align columns\n",
        "- Produce predictions `y_pred \u2208 [-1, 1]`\n",
        "- Export predictions to `outputs/eurusd_future_predictions.csv`\n",
        "- (Optional) Create trade signals with a threshold\n",
        "\n",
        "\u26a0\ufe0f Important:\n",
        "- This notebook must be run only when you have **new EUR/USD data not used in training**.\n",
        "- Do **not** refit the model here.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "ROOT = Path.cwd().parent\n",
        "SRC = ROOT / \"src\"\n",
        "if str(SRC) not in sys.path:\n",
        "    sys.path.insert(0, str(SRC))\n",
        "\n",
        "from utils import get_logger\n",
        "logger = get_logger(\"eurusd_future_test\", log_file=str(ROOT/\"logs\"/\"eurusd_future_test.log\"))\n",
        "\n",
        "logger.info(\"ROOT=%s\", ROOT)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Load frozen artifacts from notebook 09"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "out_dir = ROOT / \"outputs\"\n",
        "model_path = out_dir / \"eurusd_final_model.joblib\"\n",
        "scale_path = out_dir / \"eurusd_target_scale.joblib\"\n",
        "cols_path  = out_dir / \"eurusd_feature_columns.joblib\"\n",
        "\n",
        "assert model_path.exists(), f\"Missing model: {model_path} (run notebook 09)\"\n",
        "assert scale_path.exists(), f\"Missing scale: {scale_path} (run notebook 09)\"\n",
        "assert cols_path.exists(),  f\"Missing feature cols: {cols_path} (run notebook 09)\"\n",
        "\n",
        "model = joblib.load(model_path)\n",
        "scale = joblib.load(scale_path)\n",
        "feature_cols = joblib.load(cols_path)\n",
        "\n",
        "logger.info(\"Loaded model=%s\", model_path)\n",
        "logger.info(\"Loaded scale=%.6f\", float(scale))\n",
        "logger.info(\"Loaded %d feature columns\", len(feature_cols))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Load NEW unseen EUR/USD data\n",
        "\n",
        "Choose ONE option below:\n",
        "- **Option A:** Excel file with same structure (recommended)\n",
        "- **Option B:** CSV file with columns: Date, Open, High, Low, Close\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# -------- Option A: Excel (recommended) --------\n",
        "from data import load_ohlc_from_xlsx\n",
        "\n",
        "# Put your new file here (example path)\n",
        "TEST_XLSX = ROOT / \"data\" / \"eurusd_test.xlsx\"\n",
        "TEST_SHEET = \"EURUSD\"  # adjust if needed\n",
        "\n",
        "# If you use Option A, ensure the file exists:\n",
        "# assert TEST_XLSX.exists(), f\"Test Excel not found: {TEST_XLSX}\"\n",
        "\n",
        "# df_new = load_ohlc_from_xlsx(str(TEST_XLSX), sheet_name=TEST_SHEET)\n",
        "\n",
        "# -------- Option B: CSV --------\n",
        "# TEST_CSV = ROOT / \"data\" / \"eurusd_test.csv\"\n",
        "# df_new = pd.read_csv(TEST_CSV, parse_dates=[\"Date\"])\n",
        "\n",
        "# ---- Safety: show what you're using ----\n",
        "# logger.info(\"Loaded new data rows=%d cols=%s\", len(df_new), list(df_new.columns))\n",
        "# df_new.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Standardize / sort / sanity checks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Uncomment after loading df_new above:\n",
        "# df_new[\"Date\"] = pd.to_datetime(df_new[\"Date\"])\n",
        "# df_new = df_new.sort_values(\"Date\").reset_index(drop=True)\n",
        "\n",
        "# required_cols = {\"Date\",\"Open\",\"High\",\"Low\",\"Close\"}\n",
        "# missing = required_cols - set(df_new.columns)\n",
        "# assert not missing, f\"Missing required columns in new data: {missing}\"\n",
        "\n",
        "# logger.info(\"New data date range: %s -> %s\", df_new[\"Date\"].min(), df_new[\"Date\"].max())\n",
        "# df_new.tail()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Recompute features on new data and align with training columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from features import build_features\n",
        "\n",
        "# Uncomment after df_new is loaded:\n",
        "# df_feat = build_features(df_new).copy()\n",
        "\n",
        "# Align: ensure all expected training columns exist\n",
        "# for c in feature_cols:\n",
        "#     if c not in df_feat.columns:\n",
        "#         df_feat[c] = np.nan  # create missing columns\n",
        "\n",
        "# Keep the same order\n",
        "# X_new = df_feat[feature_cols].values\n",
        "\n",
        "# Drop rows with NaNs in features (due to rolling windows)\n",
        "# valid_mask = ~np.isnan(X_new).any(axis=1)\n",
        "# df_out = df_feat.loc[valid_mask, [\"Date\",\"Open\",\"High\",\"Low\",\"Close\"]].copy()\n",
        "# X_new = X_new[valid_mask]\n",
        "\n",
        "# logger.info(\"After feature alignment: X_new=%s (kept %d rows)\", X_new.shape, len(df_out))\n",
        "# df_out.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Predict scores on unseen data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Uncomment after X_new is built:\n",
        "# y_pred = model.predict(X_new)\n",
        "# y_pred = np.clip(y_pred, -1.0, 1.0)\n",
        "\n",
        "# df_out[\"y_pred\"] = y_pred\n",
        "\n",
        "# logger.info(\"Predictions done. y_pred stats: mean=%.4f std=%.4f min=%.4f max=%.4f\",\n",
        "#             float(np.mean(y_pred)), float(np.std(y_pred)), float(np.min(y_pred)), float(np.max(y_pred)))\n",
        "\n",
        "# df_out.tail()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Create trade signals with a threshold (optional)\n",
        "\n",
        "Interpretation:\n",
        "- `y_pred` is **signal intensity**, not a probability.\n",
        "- Use thresholds to trade only strong signals."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Uncomment after df_out[\"y_pred\"] exists:\n",
        "# threshold = 0.7\n",
        "# df_out[\"signal\"] = 0\n",
        "# df_out.loc[df_out[\"y_pred\"] > threshold, \"signal\"] = 1\n",
        "# df_out.loc[df_out[\"y_pred\"] < -threshold, \"signal\"] = -1\n",
        "\n",
        "# coverage = (df_out[\"signal\"] != 0).mean()\n",
        "# logger.info(\"Threshold=%.2f | coverage=%.2f%%\", threshold, 100*coverage)\n",
        "\n",
        "# df_out.tail()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Export predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Uncomment after df_out is ready:\n",
        "# export_path = ROOT / \"outputs\" / \"eurusd_future_predictions.csv\"\n",
        "# df_out.to_csv(export_path, index=False)\n",
        "# logger.info(\"Exported: %s\", export_path)\n",
        "\n",
        "# export_path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) Notes for future evaluation\n",
        "\n",
        "If your future test data contains enough horizon to compute `fut_ret_20`,\n",
        "we can create a proper evaluation notebook to compute IC / DirAcc / backtest.\n",
        "For now, this notebook focuses on **pure forward inference** (production-like)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}